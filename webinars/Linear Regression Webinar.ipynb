{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression Examples\n",
    "\n",
    "This Jupyter notebook presents examples building on theory from the lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Boilerplate initialisation code\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 24\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Wind tunnel data\n",
    "\n",
    "In a sequence of 8 experiments, a sensor is suspended in a wind tunnel to measure the force $F$ experienced (in Newtons) at various wind speeds $v$ (in m/s). The data is stored in the file `wind_tunnel.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/wind_tunnel.csv')  # Load data as usual using Pandas\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Generate a quick plot..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n = len(data) # number of samples\n",
    "data.plot.scatter(x='speed', y='force', marker='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Extract Numpy arrays from DataFrame for target $y$ and matrix $\\mathbf{X}$..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n = len(data) # number of samples\n",
    "y = data.force.values.reshape((n,1))\n",
    "X = np.hstack((np.ones((n,1), dtype=np.float64), data.speed.values.reshape((n,1))))\n",
    "print(X) # Preview array X; padded with column of ones as required\n",
    "print(y) # Preview target vector y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "With $\\mathbf{X}$ and $y$ as matrices, can solve linear system several ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.linalg.inv(X.T.dot(X)).dot(X.T.dot(y)) # one method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# alternative way to compute same thing\n",
    "w_LS = np.linalg.solve(np.dot(X.T, X), np.dot(X.T, y))\n",
    "print(w_LS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Produce a 2D plot showing original data and the least-squares line of best fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vv = np.linspace(0,80)        # Generate a grid of speed values\n",
    "FF = w_LS[0,0] + w_LS[1,0]*vv # Generate the corresponding force values \n",
    "plt.plot(vv, FF, 'r', X[:,1], y, 'o', markersize=7.5)\n",
    "plt.xlabel('$v$ [m/s]')\n",
    "plt.ylabel('$F$ [N]')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To get a sense of how well the line fits the data, compute the *RMSE* (*Root Mean Square Error*) and the *$R^2$ statistic*.\n",
    "\n",
    "* The RMSE is square root of the average residual squared error (i.e., find the total residual squared error divided by the number of samples and then compute the square root). In terms of the notation used so far, this is $$\\displaystyle{\\sqrt{\\frac{1}{n}\\left\\|y -\\mathbf{X}w_{LS}\\right\\|^2} = \\sqrt{\\frac{1}{n}\\sum_{k=1}^{n}\\left(y_{k} - x_{k}^{T}w_{LS}\\right)^{2}}}.$$\n",
    "* The [$R^2$ statistic (or coefficient of determination)](https://en.wikipedia.org/wiki/Coefficient_of_determination) is the fraction remaining when the ratio of the sum of the squared residuals to the total sum of squares is subtracted from one. The result is a number between 0 and 1 that quantifies how well the regression line explains the data. In effect, this is $$\\displaystyle{1 - \\left[\\sum_{k=1}^{n}\\left(y_{k}-\\overline{y}\\right)^{2}\\right]^{-1}} \\sum_{\\ell=1}^{n}\\left(y_{\\ell} - x_{\\ell}^{T}w_{LS}\\right)^{2}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here, accumulate the sum of squared residuals in `ss_r` and the sum of total squares (differences from mean of $y$) in `ss_t`. These can be used to compute the RMSE and $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ss_t = 0.0 # for accumulating the total sum of squares (i.e., differences of y[k] from y.mean() squared)\n",
    "ss_r = 0.0 # for accumulating the sum of squared residuals\n",
    "mean_y = y.mean() # compute once\n",
    "\n",
    "b0 = w_LS[0,0]\n",
    "b1 = w_LS[1,0]\n",
    "for k in range(n):\n",
    "    y_pred = b0 + b1*X[k,1]\n",
    "    ss_r += (y_pred - y[k,0]) ** 2\n",
    "    ss_t += (y[k,0] - mean_y) ** 2\n",
    "\n",
    "rmse = np.sqrt(ss_r/n)\n",
    "r2 = 1 - (ss_r/ss_t)\n",
    "print('RMSE = {}'.format(rmse))\n",
    "print('R-squared: {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Pearson's height data\n",
    "\n",
    "These are the heights of 1,078 fathers and their sons (in inches) based on a [famous experiment by Karl Pearson](http://www.randomservices.org/random/data/Pearson.html) around 1903. Random noise was added to the original data, to produce heights to the nearest 0.1 inch. The data is stored in the file `Pearson.csv`.\n",
    "\n",
    "| Father  |  Son |\n",
    "| ---  | --- |\n",
    "| 65.0 | 59.8 |\n",
    "| 63.3 | 63.2 |\n",
    "| 65.0 | 63.3 |\n",
    "| 65.8 | 62.8 |\n",
    "| 61.1 | 64.3 |\n",
    "| 63.0 | 64.2 |\n",
    "| 65.4 | 64.1 |\n",
    "| $\\vdots$ | $\\vdots$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# First, read the data into a Pandas DataFrame\n",
    "data = pd.read_csv('Pearson.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# In this instance, a scatter plot shows the spread of the data\n",
    "data.plot.scatter(x='Father', y='Son')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Again, set up the vector $y$ and matrix $\\mathbf{X}$ as required to compute the weights $w_{LS}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n = len(data)\n",
    "y = data.Son.values.reshape((n,1)) # Extract as a numpy array\n",
    "X = np.hstack( (np.ones((n, 1), dtype=np.float64), data.Father.values.reshape((n,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Finally, \"solve\" the required overdetermined system of linear equations X w = y.\n",
    "w_LS = np.linalg.solve(np.dot(X.T, X), np.dot(X.T, y))\n",
    "print(w_LS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Produce a 2D plot showing the data and the least-squares line of best fit\n",
    "FF = np.linspace(data.Father.min(), data.Father.max())\n",
    "SS = w_LS[0,0] + w_LS[1,0]*FF # Generate \n",
    "plt.plot(X[:,1], y, 'o', FF, SS, 'r', linewidth=2)\n",
    "plt.xlabel('Father heights [in]', fontsize=18)\n",
    "plt.ylabel('Son heights [in]', fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As before, compute RMSE & $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ss_t = 0.0 # for accumulating the total sum of squares (i.e., differences of y[k] from y.mean() squared)\n",
    "ss_r = 0.0 # for accumulating the sum of squared residuals\n",
    "mean_y = y.mean() # compute once\n",
    "\n",
    "b0 = w_LS[0,0]\n",
    "b1 = w_LS[1,0]\n",
    "for k in range(n):\n",
    "    y_pred = b0 + b1*X[k,1]\n",
    "    ss_r += (y_pred - y[k,0]) ** 2\n",
    "    ss_t += (y[k,0] - mean_y) ** 2\n",
    "\n",
    "rmse = np.sqrt(ss_r/n)\n",
    "r2 = 1 - (ss_r/ss_t)\n",
    "print('RMSE = {}'.format(rmse))\n",
    "print('R-squared: {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using Numpy's linear algebra utilities, above loops can be eliminated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = np.dot(X, w_LS)\n",
    "ss_r = np.linalg.norm(y_pred - y) ** 2\n",
    "rmse = np.sqrt(ss_r/n)\n",
    "print('RMSE_linalg = {}'.format(rmse)) # Same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ss_t = np.linalg.norm(y - y.mean()) ** 2\n",
    "r2 = 1-(ss_r/ss_t)\n",
    "print('R-squared_linalg = {}'.format(r2)) # Same as above (mostly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice that the $R^2$ statistic is dimensionless while the RMSE is not. The former quantifies the appropriateness of the line fit in a relative sense, whereas the RMSE gives an absolute measure of misfit (which, depending on the scaling of the problem, can be deceptive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: NHANES data\n",
    "\n",
    "The table below give the results of a random sample of size 100 from the [2005â€“2006 National Health and Nutrition Examination Survey (NHANES)](http://www.randomservices.org/random/data/NHANES.html). The variables are Gender (male or female), Age (in years), Weight (in lbs), Height, Leg length, Waist circumference, & Thigh circumference (all in inches). The data is stored in the file `NHANES.csv`.\n",
    "\n",
    "With this data, we can apply linear regression with multiple independent (or exogenous) variables; this is sometimes called *multiple linear regression*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('NHANES.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Use Pandas/Numpy techniques for filtering to separate genders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "women = (data.Gender=='F') # Define boolean series to select each gender from data\n",
    "men = ~women\n",
    "women = data.loc[women]\n",
    "men = data.loc[men]\n",
    "women.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Examine a 2D cross-section of the data stratified by gender\n",
    "plt.scatter(men.Height, men.Weight, color='r', marker='o', linewidth=5, label='Men')\n",
    "plt.scatter(women.Height, women.Weight, color='b', marker='>', linewidth=5, label='Women')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Height [in]')\n",
    "plt.ylabel('Weight [lb]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's think of Weight as a dependent variable and construct a linear regression model using the other variables (except for gender; we've separated out the two categories of subjects) as independent variables. To do this, we'll subselect a sequence of columns from the DataFrame and use those to construct a regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "n_men = len(men)\n",
    "cols = men.columns.symmetric_difference(['Gender', 'Weight'])\n",
    "men.loc[:,cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Extract target y and matrix X\n",
    "y_men = men['Weight'].values.reshape((n_men,1))\n",
    "X_men = np.concatenate((np.ones((n_men,1),dtype=np.float64), men.loc[:, cols].values), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ready to solve $w_{LS} = (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}y$ as usual..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Determine the regression weights\n",
    "w_men_LS = np.linalg.solve(np.matmul(X_men.T, X_men), np.dot(X_men.T, y_men))\n",
    "print(w_men_LS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = X_men.dot(w_men_LS)\n",
    "ss_r = np.linalg.norm(y_pred - y_men) ** 2\n",
    "ss_t = np.linalg.norm(y - y.mean()) ** 2\n",
    "rmse = np.sqrt(ss_r/n_men)\n",
    "print('RMSE_linalg = {}'.format(rmse))\n",
    "r2 = 1-(ss_r/ss_t)\n",
    "print('R-squared_linalg = {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Polynomial regression\n",
    "\n",
    "As discussed in the lectures, linear regression is *linear* due to the linear dependence on the coefficients. It is possible to have determine coefficients of linear combinations of arbitrary nonlinear functions to fit data. This is appropriate to describe trends (e.g., periodicity) that cannot be described well by degree one polynomials.\n",
    "\n",
    "As an example, let's try to fit the following points on a rectangular pulse using polynomial functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, generate the data points for the rectangular pulse..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5, 11).reshape((11,1))\n",
    "y = np.zeros((11,1))\n",
    "y[3:6] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(x, y, 'rx', markersize=7.5)\n",
    "plt.axis('equal')\n",
    "plt.ylim([-5.5, 5.5])\n",
    "plt.xlim([-2, 2])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "n = len(x)\n",
    "X = np.hstack([x**k for k in range(3)])\n",
    "\n",
    "w2 = np.linalg.solve(np.dot(X.T, X), np.dot(X.T, y))\n",
    "print(w2)\n",
    "xx = np.linspace(-5.5, 5.5, 200).reshape((200,1))\n",
    "y2 = np.hstack((np.ones((200,1)), xx, xx**2)).dot(w2) # Evaluate on grid\n",
    "\n",
    "plt.plot(x, y, 'rx', markersize=7.5, label='data')\n",
    "plt.plot(xx, y2, 'b-', linewidth=3, label='deg. 2')\n",
    "plt.axis('equal')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([-5.5, 5.5])\n",
    "plt.ylim([-2, 2])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X = np.hstack([x**k for k in range(6)])\n",
    "w5 = np.linalg.solve(np.dot(X.T, X), np.dot(X.T, y))\n",
    "print(w5)\n",
    "y5 = np.hstack((np.ones((200,1)), xx, xx**2, xx**3, xx**4, xx**5)).dot(w5) # Evaluate on grid\n",
    "\n",
    "plt.plot(x, y, 'rx', markersize=7.5, label='data')\n",
    "plt.plot(xx, y2, 'b-', linewidth=3, label='deg. 2')\n",
    "plt.plot(xx, y5, 'm.-', linewidth=3, label='deg. 5')\n",
    "plt.axis('equal')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([-5.5, 5.5])\n",
    "plt.ylim([-2, 2])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X = np.hstack([x**k for k in range(10)])\n",
    "w9 = np.linalg.solve(np.dot(X.T, X), np.dot(X.T, y))\n",
    "print(w9)\n",
    "y9 = np.hstack((np.ones((200,1)), xx, xx**2, xx**3, xx**4, \n",
    "                xx**5, xx**6, xx**7, xx**8, xx**9)).dot(w9) # Evaluate on grid\n",
    "\n",
    "plt.plot(x, y, 'rx', markersize=7.5, label='data')\n",
    "plt.plot(xx, y2, 'b-', linewidth=3, label='deg. 2')\n",
    "plt.plot(xx, y5, 'm.-', linewidth=3, label='deg. 5')\n",
    "plt.plot(xx, y9, 'k--', linewidth=3, label='deg. 9')\n",
    "plt.axis('equal')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([-5.5, 5.5])\n",
    "plt.ylim([-2, 2])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "w2_polyfit = np.polyfit(x.squeeze(), y.squeeze(), 2) # Find coefficients of degree 2 polynomial regression\n",
    "print(w2.squeeze(), w2_polyfit) # same coefficients, reverse order\n",
    "y2 = np.polyval(w2_polyfit,xx)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
