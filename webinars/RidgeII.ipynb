{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Regression: Review\n",
    "\n",
    "The Boston Housing example.\n",
    "\n",
    "| CRIM  |ZN |INDUS|CHAS| NOX | RM  |AGE | DIS |RAD|TAX|PTRATIO|  B  |LSTAT|price|\n",
    "|------:|--:|----:|---:|----:|----:|---:|----:|--:|--:|------:|----:|----:|----:|\n",
    "|0.00632| 18| 2.31|   0|0.538|6.575|65.2|4.090|  1|296|   15.3|396.9| 4.98| 24.0|\n",
    "|0.02731|  0| 7.07|   0|0.469|6.421|78.9|4.967|  2|242|   17.8|396.9| 9.14| 21.6|\n",
    "|0.02729|  0| 7.07|   0|0.469|7.185|61.1|4.967|  2|242|   17.8|392.8| 4.03| 34.7|\n",
    "|0.03237|  0| 2.18|   0|0.458|6.998|45.8|6.062|  3|222|   18.7|394.6| 2.94| 33.4|\n",
    "|0.06905|  0| 2.18|   0|0.458|7.147|54.2|6.062|  3|222|   18.7|396.9| 5.33| 36.2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.datasets import load_boston\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "X = boston.data\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "bdf = pd.DataFrame(X, columns=boston.feature_names)\n",
    "bdf['price'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#fitting a scikitlearn model\n",
    "lr = LinearRegression()\n",
    "lr.fit(bdf[['LSTAT']], y)\n",
    "prds= lr.predict(bdf[['LSTAT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#making a plot\n",
    "plt.figure(figsize = (12, 7))\n",
    "plt.scatter(bdf.LSTAT, bdf.price, label = 'Actual Price')\n",
    "plt.plot(bdf.LSTAT, prds, color = 'red', linewidth = 3, label = 'Predicted Price')\n",
    "plt.title('LSTAT vs. Price in Boston Housing', loc = 'left')\n",
    "plt.xlabel('LSTAT')\n",
    "plt.ylabel('Price')\n",
    "plt.legend(frameon = 'false')\n",
    "plt.savefig('presentation/img1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Expression\n",
    "\n",
    "$$w_{LS} = (X^TX)^{-1}X^Ty$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#calculate product inside parenthesis\n",
    "xtx = X.T@X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#find inverse\n",
    "inv = np.linalg.inv(xtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#compute weights\n",
    "wLS = inv@X.T@y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Writing a Function\n",
    "\n",
    "```\n",
    "take in X and y\n",
    "\n",
    "compute xtx\n",
    "\n",
    "compute inverse\n",
    "\n",
    "compute weights\n",
    "\n",
    "return weights\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def wLS(X, y):\n",
    "    '''\n",
    "    This function provides an \n",
    "    ordinary least squares fit of a dataset X on \n",
    "    a target variable y.\n",
    "    ----\n",
    "    X = input array of feature variables\n",
    "    y = target array of feature variables\n",
    "    returns \n",
    "    array of weights for basic linear regression\n",
    "    '''\n",
    "    #check dimensions\n",
    "    if X.shape[0] < X.shape[1]:\n",
    "        X = X.T\n",
    "    #calculate product inside parenthesis\n",
    "    xtx = X.T@X\n",
    "    #find inverse\n",
    "    inv = np.linalg.inv(xtx)\n",
    "    #compute weights\n",
    "    prod = inv@X.T\n",
    "    wLS = prod@y\n",
    "    return wLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "wLS(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classes in Python\n",
    "\n",
    "```python\n",
    "class ClassName:\n",
    "    <statement-1>\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    <statement-N>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "class MyClass:\n",
    "    \"\"\"A simple example class\"\"\"\n",
    "    i = 12345\n",
    "\n",
    "    def f(self):\n",
    "        return 'hello world'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    \"\"\"A simple example class\"\"\"\n",
    "    i = 12345\n",
    "\n",
    "    def f(self):\n",
    "        return 'hello world'\n",
    "#create an instance\n",
    "class1 = MyClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#use our method\n",
    "class1.f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `__init__ ` and `self`\n",
    "\n",
    "From the Python docs:\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "The instantiation operation (“calling” a class object) creates an empty object. Many classes like to create objects with instances customized to a specific initial state. Therefore a class may define a special method named __init__(), like this:\n",
    "<br> \n",
    " \n",
    "```\n",
    "def __init__(self):\n",
    "    self.data = []\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "class Complex:\n",
    "    def __init__(self, realpart, imagpart):\n",
    "        self.r = realpart\n",
    "        self.i = imagpart\n",
    "\n",
    "x = Complex(3.0, -4.5)\n",
    "x.r, x.i\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Complex:\n",
    "    '''\n",
    "    This is a simple class that will \n",
    "    return a complex number object.\n",
    "    '''\n",
    "    def __init__(self, realpart, imagpart):\n",
    "        self.r = realpart\n",
    "        self.i = imagpart\n",
    "\n",
    "x = Complex(3.0, -4.5)\n",
    "x.r, x.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#a different class instance\n",
    "x2 = Complex(2.3, 5.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#another class instance\n",
    "x2.r, x2.i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Our Regression Class\n",
    "\n",
    "```python\n",
    "class Regression:\n",
    "    '''\n",
    "    This class contains basic linear\n",
    "    regression capabilities.  \n",
    "    - OLS fit a linear regression model\n",
    "    - make predictions with the model\n",
    "    '''\n",
    "    def __init__(self, coefs_, intercept_):\n",
    "        self.coefs_ = None\n",
    "        self.intercept = None\n",
    "        \n",
    "    def OLS(self, X, y)\n",
    "        ...\n",
    "        self.coefs_ = wLS\n",
    "        return wLS\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return predictions\n",
    "```\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class Regression:\n",
    "    \n",
    "    def __init__(self, fit_intercept = True):\n",
    "        self.coefs_ = None\n",
    "        self.intercept_ = None\n",
    "        self._fit_intercept = fit_intercept\n",
    "        \n",
    "    \n",
    "    def OLS(self, X, y):\n",
    "        '''\n",
    "        This function provides an \n",
    "        ordinary least squares fit of a dataset X on \n",
    "        a target variable y.\n",
    "        ----\n",
    "        X = input array of feature variables\n",
    "        y = target array of feature variables\n",
    "        returns \n",
    "        array of weights for basic linear regression\n",
    "        '''\n",
    "        # Check shapes of input matricies. \n",
    "        if X.shape[0] < X.shape[1]:\n",
    "            X = X.T\n",
    "        if y.shape[0] < y.shape[1]:\n",
    "            y = y.T\n",
    "            \n",
    "        # Prepend ones to x matrix\n",
    "        if self._fit_intercept:\n",
    "            ones = np.ones((len(y), 1), dtype=int)\n",
    "            X = np.concatenate((ones, X), axis=1)\n",
    "        else:\n",
    "            X = X\n",
    "        # fit the model\n",
    "        xtx = X.T@X\n",
    "        inv = np.linalg.inv(xtx)\n",
    "        w_ls = inv@X.T@y\n",
    "        # add intercepts and coefs\n",
    "        self.intercept_ = w_ls[:1]\n",
    "        self.coefs_ = w_ls[1:]\n",
    "        return w_ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#some test cases\n",
    "lr = Regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X = np.array([[0, 2], [3, 7], [5, 9], [3.4,6]])\n",
    "y = np.array([[2.1, 3.2, 4, 5.6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lr.OLS(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#model without intercept\n",
    "lr2 = Regression(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lr2.OLS(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predict\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + X\\beta_i$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "def predict(self, X):\n",
    "    return self.intercept_ + X@self.coef_\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "del(Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class Regression:\n",
    "    \n",
    "    def __init__(self, fit_intercept = True):\n",
    "        self.coefs_ = None\n",
    "        self.intercept_ = None\n",
    "        self._fit_intercept = fit_intercept\n",
    "        \n",
    "    \n",
    "    def wLS(self, X, y):\n",
    "        '''\n",
    "        This function provides an \n",
    "        ordinary least squares fit of a dataset X on \n",
    "        a target variable y.\n",
    "        ----\n",
    "        X = input array of feature variables\n",
    "        y = target array of feature variables\n",
    "        returns \n",
    "        array of weights for basic linear regression\n",
    "        '''\n",
    "        # Check shapes of input matricies. \n",
    "        if X.shape[0] < X.shape[1]:\n",
    "            X = X.T\n",
    "        try:\n",
    "            if y.shape[0] < y.shape[1]:\n",
    "                y = y.T\n",
    "        except:\n",
    "            pass\n",
    "        # Prepend ones to x matrix\n",
    "        if self._fit_intercept:\n",
    "            ones = np.ones((len(y), 1), dtype=int)\n",
    "            X = np.concatenate((ones, X), axis=1)\n",
    "        else:\n",
    "            X = X\n",
    "        # fit the model\n",
    "        xtx = X.T@X\n",
    "        inv = np.linalg.inv(xtx)\n",
    "        w_ls = inv@X.T@y\n",
    "        # add intercepts and coefs\n",
    "        self.intercept_ = w_ls[0]\n",
    "        self.coefs_ = w_ls[1:]\n",
    "        return w_ls\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.intercept_ + X@self.coefs_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "del(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "lr = Regression()\n",
    "lr.wLS(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lr.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#testing on bigger data\n",
    "X = boston.data\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bos_reg = Regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bos_reg.wLS(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Error\n",
    "\n",
    "**Sum of squared error**: $\\sum_{i = 1}^n (\\hat{y} - y_i)^2$\n",
    "\n",
    "**Total sum of squared error**: $\\sum_{i = 1}^n (\\bar{y} - y_i)^2$\n",
    "\n",
    "**r$^2$** = $1 - \\frac{sse}{tss}$\n",
    "\n",
    "**Mean Squared Error**: $\\frac{1}{n} \\sum_{i = 1}^n (\\hat{y} - y_i)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def r2(actual_y, predicted_y):\n",
    "    sse = np.sum((predicted_y - actual_y)**2)\n",
    "    tse = np.sum((actual_y - np.mean(actual_y))**2)\n",
    "    return 1 - sse/tse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def mse(actual_y, predicted_y):\n",
    "    return np.mean((actual_y - predicted_y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    \n",
    "    def __init__(self, X, y, model):\n",
    "        self.data = X\n",
    "        self.target = y\n",
    "        self.model = model\n",
    "        \n",
    "    def r2(self):\n",
    "        squared_errors = (self.target - self.model.predict(self.data))**2\n",
    "        sse = np.sum(squared_errors)\n",
    "        tse = np.sum((self.target - np.mean(self.target))**2)\n",
    "        return 1 - sse/tse\n",
    "    \n",
    "    def mse(self):\n",
    "        return np.mean((self.target - self.model.predict(self.data))**2)\n",
    "    \n",
    "    def rmse(self):\n",
    "        return self.mse()**0.5\n",
    "    \n",
    "    def summary_printed(self):\n",
    "        print('The r2 score is {:.4}\\nThe Mean Squared Error is {:.4}\\nand the RMSE is {:.4}'.format(self.r2(), self.mse(), self.rmse()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "lr = Regression()\n",
    "lr.wLS(X, y)\n",
    "performance = Metrics(X, y, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "performance.summary_printed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y = mx + b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Polynomial Features\n",
    "\n",
    "$$ y = a + bx_i + cx_i^2 $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "x = np.array([2, 3, 4])\n",
    "poly = PolynomialFeatures(3, include_bias=False)\n",
    "poly.fit_transform(x[:, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### sklearn pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "poly_model = make_pipeline(PolynomialFeatures(7),\n",
    "                           LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "x = np.array([2, 3, 4])\n",
    "poly = PolynomialFeatures(3, include_bias=False)\n",
    "poly.fit_transform(x[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "poly_model = make_pipeline(PolynomialFeatures(7),\n",
    "                           LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#fitting a high order polynomial to sin with noise\n",
    "rng = np.random.RandomState(1)\n",
    "x = 10 * rng.rand(50)\n",
    "y = np.sin(x) + 0.1 * rng.randn(50)\n",
    "xfit = np.linspace(0, 10, 1000)\n",
    "\n",
    "poly_model.fit(x[:, np.newaxis], y)\n",
    "yfit = poly_model.predict(xfit[:, np.newaxis])\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xfit, yfit);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Any Basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "#a class for generating features from gaussian basis\n",
    "class GaussianFeatures(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Uniformly spaced Gaussian features for one-dimensional input\"\"\"\n",
    "    \n",
    "    def __init__(self, N, width_factor=2.0):\n",
    "        self.N = N\n",
    "        self.width_factor = width_factor\n",
    "    \n",
    "    @staticmethod\n",
    "    def _gauss_basis(x, y, width, axis=None):\n",
    "        arg = (x - y) / width\n",
    "        return np.exp(-0.5 * np.sum(arg ** 2, axis))\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # create N centers spread along the data range\n",
    "        self.centers_ = np.linspace(X.min(), X.max(), self.N)\n",
    "        self.width_ = self.width_factor * (self.centers_[1] - self.centers_[0])\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return self._gauss_basis(X[:, :, np.newaxis], self.centers_,\n",
    "                                 self.width_, axis=1)\n",
    "    \n",
    "gauss_model = make_pipeline(GaussianFeatures(20),\n",
    "                            LinearRegression())\n",
    "gauss_model.fit(x[:, np.newaxis], y)\n",
    "yfit = gauss_model.predict(xfit[:, np.newaxis])\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xfit, yfit)\n",
    "plt.xlim(0, 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regularization\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/b/bd/Tychonoff.jpg)\n",
    "> \"Tikhonov regularization, named for Andrey Tikhonov, is the most commonly used method of regularization of ill-posed problems. In statistics, the method is known as ridge regression, in machine learning it is known as weight decay, and with multiple independent discoveries, it is also variously known as the Tikhonov–Miller method, the Phillips–Twomey method, the constrained linear inversion method, and the method of linear regularization. It is related to the Levenberg–Marquardt algorithm for non-linear least-squares problems.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#projecting 30 gaussian basis\n",
    "model = make_pipeline(GaussianFeatures(30),\n",
    "                      LinearRegression())\n",
    "model.fit(x[:, np.newaxis], y)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xfit, model.predict(xfit[:, np.newaxis]))\n",
    "\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(-1.5, 1.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def basis_plot(model, title=None):\n",
    "    fig, ax = plt.subplots(2, sharex=True)\n",
    "    model.fit(x[:, np.newaxis], y)\n",
    "    ax[0].scatter(x, y)\n",
    "    ax[0].plot(xfit, model.predict(xfit[:, np.newaxis]))\n",
    "    ax[0].set(xlabel='x', ylabel='y', ylim=(-1.5, 1.5))\n",
    "    \n",
    "    if title:\n",
    "        ax[0].set_title(title)\n",
    "\n",
    "    ax[1].plot(model.steps[0][1].centers_,\n",
    "               model.steps[1][1].coef_)\n",
    "    ax[1].set(xlabel='basis location',\n",
    "              ylabel='coefficient',\n",
    "              xlim=(0, 10))\n",
    "    \n",
    "model = make_pipeline(GaussianFeatures(30), LinearRegression())\n",
    "basis_plot(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "model = make_pipeline(GaussianFeatures(30), Ridge(alpha=0.1))\n",
    "basis_plot(model, title='Ridge Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Intuition\n",
    "\n",
    "![](images/reg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mathematics\n",
    "\n",
    "$$\\displaystyle \\hat{\\beta}^{ridge} = (X^TX + \\lambda I)^{-1}X^Ty$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "X = boston.data\n",
    "y  = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def ridge(X, y, alpha):\n",
    "    partI = (alpha*np.eye(X.shape[1]) + X.T@X)\n",
    "    inv = np.linalg.inv(partI)\n",
    "    wrr = inv@X.T@y\n",
    "    return wrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ridge(X, y, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `sklearn` way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Ridge(alpha = 0.1).fit(X, y).coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), Ridge())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'ridge__alpha': [0.1, 1.0, 4.0, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, param_grid=params, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = BayesianRidge()\n",
    "pipe = make_pipeline(StandardScaler(), br)\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dum = DummyRegressor()\n",
    "dum.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14, 7))\n",
    "plt.plot(lr.coefs_, 'bo', label = 'linear regression')\n",
    "plt.plot(best.named_steps['ridge'].coef_, 'rx', label = 'ridge')\n",
    "plt.plot(lasso.coef_, '^', label = 'Lasso')\n",
    "plt.axhline(color = 'black', alpha = 0.4)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Reading\n",
    "\n",
    "- Blog post on writing Machine Learning classes in Python: https://dziganto.github.io/classes/data%20science/linear%20regression/machine%20learning/object-oriented%20programming/python/Understanding-Object-Oriented-Programming-Through-Machine-Learning/\n",
    "\n",
    "- The Python Data Science Handbook, *Linear Regression in Depth*: https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html\n",
    "\n",
    "- The Elements of Statistical Learning (see chapter 3): https://web.stanford.edu/~hastie/ElemStatLearn/\n",
    "\n",
    "- Andrew Ng on Regularized Methods: https://www.youtube.com/watch?v=u73PU6Qwl1I"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
